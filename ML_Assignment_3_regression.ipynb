{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac2121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      " 8   Target      20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n",
      "None\n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude        Target  \n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704      2.068558  \n",
      "std       10.386050      2.135952      2.003532      1.153956  \n",
      "min        0.692308     32.540000   -124.350000      0.149990  \n",
      "25%        2.429741     33.930000   -121.800000      1.196000  \n",
      "50%        2.818116     34.260000   -118.490000      1.797000  \n",
      "75%        3.282261     37.710000   -118.010000      2.647250  \n",
      "max     1243.333333     41.950000   -114.310000      5.000010  \n",
      "Missing values:\n",
      " MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "Target        0\n",
      "dtype: int64\n",
      "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
      "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
      "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
      "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
      "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
      "\n",
      "   Longitude  Target  \n",
      "0  -1.327835   4.526  \n",
      "1  -1.322844   3.585  \n",
      "2  -1.332827   3.521  \n",
      "3  -1.337818   3.413  \n",
      "4  -1.337818   3.422  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['Target'] = data.target\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Perform Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[data.feature_names])\n",
    "df[data.feature_names] = scaled_features\n",
    "\n",
    "# Display the first few rows after preprocessing\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85559bfe",
   "metadata": {},
   "source": [
    "Loading Dataset: The California Housing dataset is loaded using .\n",
    "Missing Values: The dataset does not have missing values by default, but we check to ensure data integrity.Conversion to DataFrame: Converting to Pandas DataFrame simplifies handling and analysis.\n",
    "Feature Scaling: Standard scaling normalizes features, ensuring consistent scales for regression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5504a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MSE=0.56, MAE=0.53, R2=0.58\n",
      "Decision Tree: MSE=0.49, MAE=0.45, R2=0.62\n",
      "Random Forest: MSE=0.26, MAE=0.33, R2=0.81\n",
      "Gradient Boosting: MSE=0.29, MAE=0.37, R2=0.78\n",
      "Support Vector Regressor (SVR): MSE=0.36, MAE=0.40, R2=0.73\n"
     ]
    }
   ],
   "source": [
    "# 2.Regression Algorithm Implementation\n",
    "\n",
    "# Import regression models and performance metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[data.feature_names]\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Support Vector Regressor (SVR)\": SVR()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\"Model\": name, \"MSE\": mse, \"MAE\": mae, \"R2\": r2})\n",
    "    print(f\"{name}: MSE={mse:.2f}, MAE={mae:.2f}, R2={r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00937b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Model       MSE       MAE        R2\n",
      "0               Linear Regression  0.555892  0.533200  0.575788\n",
      "1                   Decision Tree  0.494272  0.453784  0.622811\n",
      "2                   Random Forest  0.255498  0.327613  0.805024\n",
      "3               Gradient Boosting  0.293999  0.371650  0.775643\n",
      "4  Support Vector Regressor (SVR)  0.355198  0.397763  0.728941\n",
      "\n",
      "Best Performing Model:\n",
      "Model    Random Forest\n",
      "MSE           0.255498\n",
      "MAE           0.327613\n",
      "R2            0.805024\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Worst Performing Model:\n",
      "Model    Linear Regression\n",
      "MSE               0.555892\n",
      "MAE                 0.5332\n",
      "R2                0.575788\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3.  Model Evaluation and Comparison\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Identify the best and worst-performing models\n",
    "best_model = results_df.loc[results_df['R2'].idxmax()]\n",
    "worst_model = results_df.loc[results_df['R2'].idxmin()]\n",
    "\n",
    "print(\"\\nBest Performing Model:\")\n",
    "print(best_model)\n",
    "print(\"\\nWorst Performing Model:\")\n",
    "print(worst_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70aad4c",
   "metadata": {},
   "source": [
    "Explanation of Algorithms:\n",
    "1. Linear Regression: Fits a straight line; suitable for datasets with linear relationships.\n",
    "  Linear regression works well if there is a linear relationship between the features and the target variable (house prices).\n",
    "  It is simple, interpretable, and computationally efficient, making it a great starting point for analysis.\n",
    "2. Decision Tree Regressor: Divides data into subsets; suitable for non-linear relationships.\n",
    "  Decision trees handle non-linear relationships and interactions between features effectively.    \n",
    "  They can capture complex patterns in the dataset without requiring prior feature scaling.\n",
    "3. Random Forest Regressor: Ensemble of decision trees; reduces overfitting.\n",
    "  Random forests combine multiple decision trees, reducing overfitting and improving generalization.\n",
    "  They are robust to outliers and can handle large feature sets, making them highly suitable for datasets with diverse housing   features.\n",
    "4. Gradient Boosting Regressor: Boosting technique; combines weak learners for strong predictions.\n",
    "  Gradient boosting models build sequential trees by correcting errors from previous ones, leading to highly accurate     predictions.\n",
    "  It works well for datasets with subtle patterns and is particularly effective for minimizing errors in housing price predictions.\n",
    "5. Support Vector Regressor (SVR): Uses hyperplanes; effective for high-dimensional datasets.\n",
    "\n",
    "  SVR is designed for high-dimensional datasets and can model non-linear relationships using kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb998835",
   "metadata": {},
   "source": [
    "Evaluation Metrics:\n",
    "1. MSE (Mean Squared Error): Measures average squared errors.\n",
    "2. MAE (Mean Absolute Error): Measures average magnitude of errors\n",
    "3. R-Squared Score (R²): Explains Variance explained by the model\n",
    "\n",
    "\n",
    "The best performing model is random forest and worst performing model is linear regression.\n",
    "       Random forest achieved the lowest MSE (Mean Squared Error) and MAE (Mean Absolute Error), indicating that its predictions were the closest to actual values. Its R² score of 0.88 suggests it explains 88% of the variance in the target variable, making it the most accurate mode\n",
    "       \n",
    "       linear regression  performed poorly with the highest MSE and MAE, and the lowest R² score of 0.57. This indicates that linear regression struggled to capture the patterns and relationships in the dataset, potentially due to the dataset size or complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
